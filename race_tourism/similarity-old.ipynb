{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from modelscope.msdatasets import MsDataset\n",
    "import torch\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "def load_test_data(test_file):\n",
    "    test_data = []\n",
    "    with open(test_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            test_data.append(json.loads(line.strip()))\n",
    "    return test_data\n",
    "\n",
    "def main():\n",
    "    print(\"start\")\n",
    "    # Initialize the embedding model\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name='BAAI/bge-large-zh-v1.5')\n",
    "\n",
    "    # Load test data\n",
    "    test_data = load_test_data('eval_only_query.jsonl')\n",
    "    test_queries = [item['query'] for item in test_data]\n",
    "    test_embeddings = embedding_model.embed_documents(test_queries)\n",
    "\n",
    "    # Similarity threshold\n",
    "    threshold = 0.7\n",
    "\n",
    "    # Open file to write similar pairs\n",
    "    similar_file = open('similar_pairs.jsonl', 'w', encoding='utf-8')\n",
    "\n",
    "    # Load training data and build Faiss index\n",
    "    ds = MsDataset.load('BAAI/IndustryCorpus2_tourism_geography')\n",
    "    corpus_texts = []\n",
    "    corpus_embeddings = []\n",
    "\n",
    "    # Build the index in batches to handle large datasets\n",
    "    batch_size = 100000  # Adjust based on your memory capacity\n",
    "    index = None  # Initialize the Faiss index\n",
    "\n",
    "    for idx, train_item in enumerate(tqdm(ds, desc=\"Loading and indexing corpus\")):\n",
    "        train_text = train_item['text']  # Adjust if the field is different\n",
    "        corpus_texts.append(train_text)\n",
    "\n",
    "        # When batch is full or it's the last item, process the batch\n",
    "        if len(corpus_texts) >= batch_size or idx == len(ds) - 1:\n",
    "            # Embed the corpus texts\n",
    "            batch_embeddings = embedding_model.embed_documents(corpus_texts)\n",
    "\n",
    "            if index is None:\n",
    "                # Initialize the Faiss index\n",
    "                index = FAISS(np.array(batch_embeddings), corpus_texts)\n",
    "            else:\n",
    "                # Add to existing Faiss index\n",
    "                index.add_vectors(np.array(batch_embeddings), corpus_texts)\n",
    "\n",
    "            # Clear the lists for the next batch\n",
    "            corpus_texts = []\n",
    "\n",
    "    # Search for similar texts for each test query\n",
    "    for test_query, test_embedding in tqdm(zip(test_queries, test_embeddings), desc=\"Searching for similar texts\", total=len(test_queries)):\n",
    "        # Query the Faiss index\n",
    "        similar_docs = index.similarity_search_by_vector(test_embedding, k=10)  # Adjust 'k' as needed\n",
    "\n",
    "        # Filter results by similarity threshold\n",
    "        for doc in similar_docs:\n",
    "            # Compute similarity manually since Faiss returns approximate distances\n",
    "            similarity = np.dot(test_embedding, embedding_model.embed_documents([doc.page_content])[0]) / \\\n",
    "                         (np.linalg.norm(test_embedding) * np.linalg.norm(embedding_model.embed_documents([doc.page_content])[0]))\n",
    "            if similarity > threshold:\n",
    "                similar_entry = {\n",
    "                    'train_text': doc.page_content,\n",
    "                    'similarity': similarity\n",
    "                }\n",
    "                similar_file.write(json.dumps(similar_entry, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    similar_file.close()\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
